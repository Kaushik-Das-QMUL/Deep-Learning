{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdmQ0JbImys_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a99a124-b280-45db-9953-d583f127eaa7"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, Dropout, Input, BatchNormalization, Flatten, Reshape, ZeroPadding2D, Activation\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhlN_mI9VQm0",
        "colab_type": "text"
      },
      "source": [
        "Based on Ian Goodfellow's Paper GAN is developed. However, DCGAN is advanced version of GAN which is developed here based on Alec Radford, Luke Metz, Soumith Chintala's Paper \"UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS\". But, The idea is very much similar to GOODFELLOW'S GAN Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqJfsrfnlMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.img_rows = 28\n",
        "    self.img_cols = 28\n",
        "    self.channels = 1\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels) #Channels is optional\n",
        "    self.latent_dim = 100\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    self.D = self.create_discriminator()\n",
        "    self.D.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    self.G = self.create_generator()\n",
        "    z = Input(shape=(self.latent_dim,))\n",
        "    counterfiet= self.G(z)\n",
        "    self.D.trainable=False\n",
        "    police= self.D(counterfiet)\n",
        "    self.dcgan=Model(inputs=z, outputs=police)\n",
        "    self.dcgan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "  def create_generator(self):\n",
        "    generator_model=Sequential()\n",
        "\n",
        "    #Initial Shape 7x7. Two times Upsample will make it 28*28\n",
        "    \n",
        "    generator_model.add(Dense(256*7*7, activation = LeakyReLU(0.2), input_dim = self.latent_dim))\n",
        "    generator_model.add(Reshape((7, 7, 256)))\n",
        "    generator_model.add(UpSampling2D())\n",
        "\n",
        "    generator_model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    generator_model.add(BatchNormalization(momentum=0.8))\n",
        "    generator_model.add(Activation(LeakyReLU(0.2)))\n",
        "    generator_model.add(UpSampling2D())\n",
        "\n",
        "    generator_model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    generator_model.add(BatchNormalization(momentum=0.8))\n",
        "    generator_model.add(Activation(LeakyReLU(0.2)))\n",
        "   \n",
        "    generator_model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "    generator_model.add(Activation(\"tanh\"))\n",
        "\n",
        "    noise = Input(shape=(self.latent_dim,))\n",
        "    gen_img = generator_model(noise)\n",
        "\n",
        "    return Model(inputs=noise , outputs=gen_img)\n",
        "\n",
        "  \n",
        "  def create_discriminator(self):\n",
        "\n",
        "    discriminator_model = Sequential()\n",
        "\n",
        "    discriminator_model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "    discriminator_model.add(LeakyReLU(alpha=0.2))\n",
        "    discriminator_model.add(Dropout(0.25))\n",
        "\n",
        "    discriminator_model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    discriminator_model.add(ZeroPadding2D(padding=((0,1),(0,1)))) #Pad Bottom and Right Respectively\n",
        "    discriminator_model.add(BatchNormalization(momentum=0.8))\n",
        "    discriminator_model.add(LeakyReLU(alpha=0.2))\n",
        "    discriminator_model.add(Dropout(0.25))\n",
        "\n",
        "    discriminator_model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    discriminator_model.add(BatchNormalization(momentum=0.8))\n",
        "    discriminator_model.add(LeakyReLU(alpha=0.2))\n",
        "    discriminator_model.add(Dropout(0.25))\n",
        "\n",
        "    discriminator_model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    discriminator_model.add(BatchNormalization(momentum=0.8))\n",
        "    discriminator_model.add(LeakyReLU(alpha=0.2))\n",
        "    discriminator_model.add(Dropout(0.25))\n",
        "\n",
        "    discriminator_model.add(Flatten())\n",
        "    discriminator_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    validity = discriminator_model(img)\n",
        "\n",
        "    return Model(inputs=img, outputs=validity)\n",
        "\n",
        "  def training(self, epochs, batch_size=128, sample_interval=10000):\n",
        "\n",
        "    (X_train , _), (_ , _) = mnist.load_data()\n",
        "    X_train = X_train/127.5 -1\n",
        "    X_train = np.expand_dims(X_train, axis=3) #In Order to add the channel Information\n",
        "\n",
        "    #Truth Value\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in tqdm_notebook(range(epochs+1)):\n",
        "\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "      self.dcgan.train_on_batch(noise, valid) #Fooling Tricks\n",
        "      gen_imgs = self.G.predict(noise)\n",
        "\n",
        "      self.D.train_on_batch(imgs, valid)\n",
        "      self.D.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "      if epoch % sample_interval == 0:\n",
        "        self.sample_images(epoch)\n",
        "\n",
        "  \n",
        "  def sample_images(self, epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "    gen_imgs = self.G.predict(noise)\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axis = plt.subplots(r, c, figsize=(5, 5))\n",
        "\n",
        "    for m, n in itertools.product(range(5), range(5)):\n",
        "      axis[m, n].get_xaxis().set_visible(False)\n",
        "      axis[m, n].get_yaxis().set_visible(False)\n",
        "\n",
        "    for i in range(25):\n",
        "      row = i // 5\n",
        "      col = i % 5\n",
        "      axis[row, col].cla()    #Clear the current axes.\n",
        "      axis[row, col].imshow(np.reshape(gen_imgs[i], (28, 28)), cmap='gray')\n",
        "\n",
        "    plt.savefig('gan_generated_image %d.png' %epoch)\n",
        "    plt.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvDogAo68wG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  dcgan = DCGAN()\n",
        "  dcgan.training(epochs=80000, batch_size=128, sample_interval=10000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}