{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_&Recurrent CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aAjzPdoKkNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape,BatchNormalization,Activation\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from PIL import Image as pil_image\n",
        "import cv2 as cv2\n",
        "from  skimage import transform\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HngisdM5vycm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_shape = (56,56)\n",
        "# x_train = np.asarray([transform.resize(image, new_shape) for image in x_train])\n",
        "# x_test = np.asarray([transform.resize(image, new_shape) for image in x_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKqGi3S03LqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training data Dimension : ', x_train.shape, y_train.shape)\n",
        "print('Testing data Dimension : ', x_test.shape, y_test.shape)\n",
        "classes = np.unique(y_train)\n",
        "number_of_classes = len(classes)\n",
        "print(number_of_classes)\n",
        "\n",
        "plt.figure(figsize=[2,2])\n",
        "plt.imshow(x_train[10,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(y_train[10]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLXvZkeD9rI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb1f77b4-8a25-4707-d69c-314799fc15ab"
      },
      "source": [
        "ch=1\n",
        "rows, cols = 28,28\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], ch, rows, cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], ch, rows, cols)\n",
        "    input_shape = (ch, rows, cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], rows, cols, ch)\n",
        "    x_test = x_test.reshape(x_test.shape[0], rows, cols, ch)\n",
        "    input_shape = (rows, cols, ch)\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ST3qwwV-nYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2900ba4a-df45-47df-8120-88acc7fed5c4"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, number_of_classes)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test, number_of_classes)\n",
        "\n",
        "print('Original label : ', y_train[10])\n",
        "print('After One Hot Encoding : ', y_train_one_hot[10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original label :  3\n",
            "After One Hot Encoding :  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsNYG0esucSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vgg_model = Sequential()\n",
        "\n",
        "vgg_model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = 'relu', kernel_initializer=keras.initializers.he_normal(seed=None), input_shape = input_shape))  \n",
        "vgg_model.add(BatchNormalization(axis=-1))   \n",
        "vgg_model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu')) \n",
        "vgg_model.add(BatchNormalization(axis=-1))               \n",
        "#vgg_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))                                                     \n",
        "\n",
        "vgg_model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu')) \n",
        "vgg_model.add(BatchNormalization(axis=-1))                \n",
        "vgg_model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))\n",
        "vgg_model.add(BatchNormalization(axis=-1))                 \n",
        "vgg_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))                                                     \n",
        "\n",
        "vgg_model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu')) \n",
        "vgg_model.add(BatchNormalization(axis=-1))                \n",
        "vgg_model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))  \n",
        "vgg_model.add(BatchNormalization(axis=-1))               \n",
        "vgg_model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))  \n",
        "vgg_model.add(BatchNormalization(axis=-1))               \n",
        "vgg_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))                                                      \n",
        "\n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu')) \n",
        "vgg_model.add(BatchNormalization(axis=-1))                \n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))\n",
        "vgg_model.add(BatchNormalization(axis=-1))                \n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))   \n",
        "vgg_model.add(BatchNormalization(axis=-1))              \n",
        "#vgg_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))                                                         \n",
        "\n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))  \n",
        "vgg_model.add(BatchNormalization(axis=-1))               \n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu'))  \n",
        "vgg_model.add(BatchNormalization(axis=-1))               \n",
        "vgg_model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = \"same\",kernel_initializer=keras.initializers.he_normal(seed=None), activation = 'relu')) \n",
        "vgg_model.add(BatchNormalization(axis=-1))                \n",
        "vgg_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))                                                         \n",
        "\n",
        "vgg_model.add(Flatten())\n",
        "vgg_model.add(Dense(units=4096,kernel_initializer=keras.initializers.he_normal(seed=None),activation=\"relu\")) \n",
        "vgg_model.add(BatchNormalization())                                                              \n",
        "vgg_model.add(Dense(units=4096,kernel_initializer=keras.initializers.he_normal(seed=None),activation=\"relu\"))\n",
        "vgg_model.add(BatchNormalization())                                                               \n",
        "vgg_model.add(Dense(number_of_classes, activation='softmax'))                                                   #10 Classes     (Layer-16)\n",
        "\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdwTRBiLAmtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.01,decay=1e-6, momentum=0.9, nesterov=True)\n",
        "batch_size = 128\n",
        "number_of_epoch = 20\n",
        "vgg_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = vgg_model.fit(x_train, y_train_one_hot, validation_split=0.1, epochs=number_of_epoch, batch_size=batch_size, verbose=1, shuffle=1)\n",
        "\n",
        "report_card = vgg_model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
        "print('Test loss:', report_card[0])\n",
        "print('Test accuracy:', report_card[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu1d4iZprFun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwYlqLfFx_ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('epoch')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0UPwBdbIDWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "from keras.layers import merge, Convolution2D, MaxPooling2D, Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def makeModel(nbChannels, shape1, shape2, nbClasses, nbRCL=5,\n",
        "\t\t nbFilters=128, filtersize = 3):\n",
        "\n",
        "\n",
        "\tmodel = BuildRCNN(nbChannels, shape1, shape2, nbClasses, nbRCL, nbFilters, filtersize)\n",
        "\treturn model\n",
        "\n",
        "def BuildRCNN(nbChannels, shape1, shape2, nbClasses, nbRCL, nbFilters, filtersize):\n",
        "    \n",
        "    def RCL_block(l_settings, l, pool=True, increase_dim=False):\n",
        "        input_num_filters = l_settings.output_shape[3]\n",
        "        if increase_dim:\n",
        "            out_num_filters = input_num_filters*2\n",
        "        else:\n",
        "            out_num_filters = input_num_filters\n",
        "\t\t   \n",
        "        conv1 = Convolution2D(out_num_filters, 1, 1, border_mode='same')\n",
        "        stack1 = conv1(l)   \t\n",
        "        stack2 = BatchNormalization()(stack1)\n",
        "        stack3 = PReLU()(stack2)\n",
        "        \n",
        "        conv2 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', init = 'he_normal')\n",
        "        stack4 = conv2(stack3)\n",
        "        stack5 = keras.layers.merge.Add()([stack1, stack4])\n",
        "        stack6 = BatchNormalization()(stack5)\n",
        "        stack7 = PReLU()(stack6)\n",
        "    \t\n",
        "        conv3 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', weights = conv2.get_weights())\n",
        "        stack8 = conv3(stack7)\n",
        "        stack9 = keras.layers.merge.Add()([stack1, stack8])\n",
        "        stack10 = BatchNormalization()(stack9)\n",
        "        stack11 = PReLU()(stack10)    \n",
        "        \n",
        "        conv4 = Convolution2D(out_num_filters, filtersize, filtersize, border_mode='same', weights = conv2.get_weights())\n",
        "        stack12 = conv4(stack11)\n",
        "        stack13 = keras.layers.merge.Add()([stack1, stack12])\n",
        "        stack14 = BatchNormalization()(stack13)\n",
        "        stack15 = PReLU()(stack14)    \n",
        "        \n",
        "        if pool:\n",
        "            stack16 = MaxPooling2D((2, 2), border_mode='same')(stack15) \n",
        "            stack17 = Dropout(0.1)(stack16)\n",
        "        else:\n",
        "            stack17 = Dropout(0.1)(stack15)\n",
        "            \n",
        "        return stack17\n",
        "\n",
        "    #Build Network\n",
        "    input_img = Input(shape=(shape1, shape2, nbChannels))\n",
        "    conv_l = Convolution2D(nbFilters, filtersize, filtersize, border_mode='same', activation='relu')\n",
        "    l = conv_l(input_img)\n",
        "    \n",
        "    for n in range(nbRCL):\n",
        "        if n % 2 ==0:\n",
        "            l = RCL_block(conv_l, l, pool=False)\n",
        "        else:\n",
        "            l = RCL_block(conv_l, l, pool=True)\n",
        "    \n",
        "    out = Flatten()(l)        \n",
        "    l_out = Dense(nbClasses, activation = 'softmax')(out)\n",
        "    \n",
        "    model = Model(input = input_img, output = l_out)\n",
        "    \n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Eq9AJ6Mjzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nbChannels = 1\n",
        "shape1 = 28\n",
        "shape2 = 28\n",
        "nbClasses = 10\n",
        "nbRCL = 5\n",
        "nbFilters = 128\n",
        "filtersize =3\n",
        "\n",
        "model = BuildRCNN(nbChannels, shape1, shape2, nbClasses, nbRCL, nbFilters, filtersize)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "history = model.fit(x_train, y_train_one_hot, validation_split=0.1, epochs=10, batch_size=128, verbose=1, shuffle=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}