{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogLeNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBeY-shTvgGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be7e5794-d152-4a46-be0b-715dd1b2fb07"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape, BatchNormalization, Activation,Convolution2D\n",
        "from keras.layers import Input, Add, ZeroPadding2D, AveragePooling2D, GlobalMaxPooling2D, add, Concatenate\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as k\n",
        "from keras.optimizers import Adam\n",
        "from PIL import Image as pil_image\n",
        "from keras.models import Model\n",
        "from PIL import Image as pil_image\n",
        "import cv2 as cv2\n",
        "from  skimage import transform\n",
        "from keras import optimizers\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isZ7sTQQwQU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Training data Dimension : ', x_train.shape, y_train.shape)\n",
        "print('Testing data Dimension : ', x_test.shape, y_test.shape)\n",
        "classes = np.unique(y_train)\n",
        "number_of_classes = len(classes)\n",
        "print(number_of_classes)\n",
        "\n",
        "plt.figure(figsize=[2,2])\n",
        "plt.imshow(x_train[1000,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(y_train[10]))\n",
        "print(x_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A09R-hbgw6N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, number_of_classes)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test, number_of_classes)\n",
        "\n",
        "print('Original label : ', y_train[10])\n",
        "print('After One Hot Encoding : ', y_train_one_hot[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVQEp_f6w-ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows, cols = 28,28\n",
        "ch=1\n",
        "if k.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], ch, rows, cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], ch, rows, cols)\n",
        "    input_shape = (ch, rows, cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], rows, cols, ch)\n",
        "    x_test = x_test.reshape(x_test.shape[0], rows, cols, ch)\n",
        "    input_shape = (rows, cols, ch)\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_eHKg40xBXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Inception_Module(X,Filter, Name):\n",
        "\n",
        "  one_one_conv = Conv2D(filters = Filter[0], kernel_size=1, strides=(1,1), padding='same', kernel_initializer=keras.initializers.he_normal(seed=0), activation='relu' , name = Name + 'p_1_1' )(X)\n",
        "\n",
        "  three_three_conv_step_1 = Conv2D(filters = Filter[1][0], kernel_size = 1, strides = (1,1), padding = 'same', kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name = Name + 'p_2_1')(X)\n",
        "  three_three_conv_step_2 = Conv2D(filters = Filter[1][1], kernel_size = 3, strides = (1,1), padding = 'same', kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name = Name + 'p_2_2')(three_three_conv_step_1)\n",
        "\n",
        "  five_five_conv_step_1 = Conv2D(filters = Filter[2][0], kernel_size = 1, strides = (1,1), padding = 'same', kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu' , name = Name + 'p_3_1')(X)\n",
        "  five_five_conv_step_2 = Conv2D(filters = Filter[2][1], kernel_size = 5, strides = (1,1), padding = 'same', kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name = Name + 'p_3_2')(five_five_conv_step_1)\n",
        "\n",
        "  max_pooling_layer_step_1 = MaxPooling2D(pool_size = (3,3), strides = 1, padding = 'same', name= Name + 'p_4_1')(X)\n",
        "  max_pooling_layer_step_2 = Conv2D(filters = Filter[3], kernel_size = 1, strides = (1,1), padding = 'same', kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name= Name + 'p_4_2')(max_pooling_layer_step_1)\n",
        "\n",
        "  #return Concatenate([one_one_conv, three_three_conv_step_2, five_five_conv_step_2, max_pooling_layer_step_2],axis = 1 name = Name)\n",
        "  return Concatenate(axis = -1)([one_one_conv, three_three_conv_step_2, five_five_conv_step_2, max_pooling_layer_step_2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJRMZ1BX2p-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GoogLeNet():\n",
        "\n",
        "  X = Input(input_shape, name='Input')\n",
        "  first_l = Conv2D(64, kernel_size = 3, padding = 'same', strides = (1,1), kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name='conv_1st')(X)\n",
        "  first_l =BatchNormalization(axis=-1)(first_l)\n",
        "\n",
        "  second_l = Conv2D(192, kernel_size = 3, padding = 'same', strides = (1,1), kernel_initializer=keras.initializers.he_normal(seed=0), activation = 'relu', name='conv_2nd')(first_l)\n",
        "  second_l =BatchNormalization(axis=-1)(second_l)\n",
        "  \n",
        "  three_a = Inception_Module(second_l, [64, (96,128), (16,32), 32], 'three_a_')\n",
        "  three_a =BatchNormalization(axis=-1)(three_a)\n",
        "\n",
        "  three_b = Inception_Module(three_a, [128, (128,192), (32,96), 64], 'three_b_')\n",
        "  three_b =BatchNormalization(axis=-1)(three_b)\n",
        "\n",
        "  Maxpool_Layer_1 = MaxPooling2D((2,2), strides = (2,2), name = 'Maxpool_After_Stage_3')(three_b)\n",
        "\n",
        "  four_a =  Inception_Module(Maxpool_Layer_1, [192, (96,208), (16,48), 64], 'four_a_')\n",
        "  four_a =BatchNormalization(axis=-1)(four_a)\n",
        "\n",
        "  four_b =  Inception_Module(four_a, [160, (112,224),  (24,64),  64], 'four_b_')\n",
        "  four_b =BatchNormalization(axis=-1)(four_b)\n",
        "\n",
        "  four_c =  Inception_Module(four_b, [128, (128,256),  (24,64),  64], 'four_c_')\n",
        "  four_c =BatchNormalization(axis=-1)(four_c)\n",
        "\n",
        "  four_d =  Inception_Module(four_c, [192, (96,208), (16,64), 64], 'four_d_')\n",
        "  four_d =BatchNormalization(axis=-1)(four_d)\n",
        "\n",
        "  four_e =  Inception_Module(four_d, [256, (160,320), (32,128), 128], 'four_e_')\n",
        "  four_e =BatchNormalization(axis=-1)(four_e)\n",
        "\n",
        "  Maxpool_Layer_2 = MaxPooling2D((2,2), strides = (2,2), name = 'Maxpool_After_Stage_4')(four_e)\n",
        "\n",
        "  five_a =  Inception_Module(Maxpool_Layer_2, [256, (160,320), (32,128), 128], 'five_a_')\n",
        "  five_a =BatchNormalization(axis=-1)(five_a)\n",
        "\n",
        "  five_b =  Inception_Module(five_a, [160, (112,224),  (24,64),  64], 'five_b_')\n",
        "  five_b =BatchNormalization(axis=-1)(five_b)\n",
        "\n",
        "  Average_pool = AveragePooling2D((7,7), strides = (1,1), padding='valid', name=\"Average_pooling_Layer\")(five_b)\n",
        "\n",
        "\n",
        "  Flatten_Layer = Flatten()(Average_pool)\n",
        "  Dropout_Layer = Dropout(0.4, name='Dropout_Layer_1')(Flatten_Layer)\n",
        "  Dense_layer = Dense(units=256, activation='relu', name='Dense_layer_1')(Dropout_Layer)\n",
        "  output_Layer = Dense(units=10, activation='softmax', name='output_layer')(Dense_layer)\n",
        "  \n",
        "  model = Model(inputs = X, outputs = output_Layer)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZzP_kTU2Cdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "f7c63086-bb7e-4848-d954-d890ce667258"
      },
      "source": [
        "GoogLeNet_Model = GoogLeNet();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCHe7xM8aGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GoogLeNet_Model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v55aQ8JtHJfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optimizers.SGD(lr=0.01,decay=1e-6, momentum=0.9, nesterov=True)\n",
        "GoogLeNet_Model.compile(loss=keras.losses.categorical_crossentropy, optimizer=sgd, metrics=['accuracy'])\n",
        "batch_size = 256\n",
        "number_of_epoch = 10\n",
        "\n",
        "history = GoogLeNet_Model.fit(x_train, y_train_one_hot, validation_split=0.1, epochs=number_of_epoch, batch_size=batch_size, verbose=1, shuffle=1)\n",
        "report_card = GoogLeNet_Model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
        "print('Test loss:', report_card[0])\n",
        "print('Test accuracy:', report_card[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Jt9U162g9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN1kYHhD2iN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('epoch')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}