{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\n\ncontent_path = '../input/neuralstyletransferdata/Content_Kaushik.jpg'\nstyle_path = '../input/neural-style-transfer-data/Style.jpeg'","metadata":{"id":"fFfspOt8E6a4","execution":{"iopub.status.busy":"2021-09-23T12:12:18.644134Z","iopub.execute_input":"2021-09-23T12:12:18.64482Z","iopub.status.idle":"2021-09-23T12:12:18.741733Z","shell.execute_reply.started":"2021-09-23T12:12:18.644582Z","shell.execute_reply":"2021-09-23T12:12:18.740707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# import tf.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import vgg19\nfrom tensorflow.keras.models import Model\n\ntf.config.run_functions_eagerly(True)","metadata":{"id":"CVsyQkOLM75d","execution":{"iopub.status.busy":"2021-09-23T12:12:18.744173Z","iopub.execute_input":"2021-09-23T12:12:18.744607Z","iopub.status.idle":"2021-09-23T12:12:20.586378Z","shell.execute_reply.started":"2021-09-23T12:12:18.744556Z","shell.execute_reply":"2021-09-23T12:12:20.585378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_nrows, img_ncols = 784, 784\ndef preprocess_image(path):\n    img = load_img(path, target_size = (img_nrows, img_ncols))\n    img = img_to_array(img) #Converts a PIL Image instance to a Numpy array.\n    img = np.expand_dims(img, axis = 0)\n    img = vgg19.preprocess_input(img)\n    return img","metadata":{"id":"XSxEyVCqNKnz","execution":{"iopub.status.busy":"2021-09-23T12:12:20.588128Z","iopub.execute_input":"2021-09-23T12:12:20.588522Z","iopub.status.idle":"2021-09-23T12:12:20.59621Z","shell.execute_reply.started":"2021-09-23T12:12:20.58848Z","shell.execute_reply":"2021-09-23T12:12:20.59505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gram_matrix(ip_tensor):\n    t = tf.transpose(ip_tensor, (2,0,1))    # making the input tensor as n_c x n_h x n_w\n    features = tf.reshape(t, (tf.shape(t)[0], -1)) # making the tensor to n_c x (n_h * n_w) dimensional\n    gram_matrix = tf.matmul(features, tf.transpose(features))\n    return gram_matrix\n\ndef compute_style_loss (style_img, generated_img):\n    S = gram_matrix(style_img)\n    G = gram_matrix(generated_img)\n    ch = 3\n    size = (img_nrows * img_ncols)\n    J_Style = K.sum(K.square(S - G))/ (4.0 * (ch ** 2) * (size ** 2))\n    return J_Style\n\ndef compute_content_loss(content_img, generated_img):\n    J_Content = K.sum(K.square(generated_img - content_img ))\n    return J_Content","metadata":{"id":"Tr_XZIGtjsMS","execution":{"iopub.status.busy":"2021-09-23T12:12:20.598089Z","iopub.execute_input":"2021-09-23T12:12:20.598457Z","iopub.status.idle":"2021-09-23T12:12:20.61176Z","shell.execute_reply.started":"2021-09-23T12:12:20.598415Z","shell.execute_reply":"2021-09-23T12:12:20.610747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_loss(generated_img, content_img, style_img):\n    input_tensor = K.concatenate([content_image, style_image, generated_img], axis = 0)\n    feature = feature_extractors(input_tensor)\n    loss = K.variable(0.0)\n    layer_feature = feature[content_layer]\n\n    content_img_feature = layer_feature[0,:,:,:]\n    generated_img_feature = layer_feature[2,:,:,:]\n\n    loss = loss + content_weight * compute_content_loss(content_img_feature, generated_img_feature)\n\n    for layer_name in style_layers:\n        layer_feature = feature[layer_name]\n        style_img_feature = layer_feature[1,:,:,:]\n        generated_img_feature = layer_feature[2,:,:,:]\n\n        loss = loss + (style_weight/len(style_layers)) * compute_style_loss(style_img_feature, generated_img_feature)\n\n    return loss\n\n\n\"\"\"Error in the above function\"\"\"","metadata":{"id":"9NWeuUnn1zS_","outputId":"1495515b-00e6-41a4-984f-c53b7736d400","execution":{"iopub.status.busy":"2021-09-23T12:12:20.615909Z","iopub.execute_input":"2021-09-23T12:12:20.616209Z","iopub.status.idle":"2021-09-23T12:12:20.632481Z","shell.execute_reply.started":"2021-09-23T12:12:20.616132Z","shell.execute_reply":"2021-09-23T12:12:20.631237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef compute_loss_and_grads(combination_image, base_image, style_reference_image):\n    with tf.GradientTape() as tape:\n        loss = compute_loss(combination_image, base_image, style_reference_image)\n    grads = tape.gradient(loss, combination_image)\n    return loss, grads","metadata":{"id":"N6NvTK929ktV","execution":{"iopub.status.busy":"2021-09-23T12:12:20.634374Z","iopub.execute_input":"2021-09-23T12:12:20.635056Z","iopub.status.idle":"2021-09-23T12:12:20.644459Z","shell.execute_reply.started":"2021-09-23T12:12:20.635011Z","shell.execute_reply":"2021-09-23T12:12:20.643484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deprocess_image(x):\n\n    x = x.reshape((img_nrows, img_ncols, 3))\n    # Remove zero-center by mean pixel\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    # 'BGR'->'RGB'\n    x = x[:, :, ::-1]\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x","metadata":{"id":"EGtSxEQ7MEz1","execution":{"iopub.status.busy":"2021-09-23T12:12:20.64696Z","iopub.execute_input":"2021-09-23T12:12:20.647238Z","iopub.status.idle":"2021-09-23T12:12:20.655807Z","shell.execute_reply.started":"2021-09-23T12:12:20.647197Z","shell.execute_reply":"2021-09-23T12:12:20.654642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n# tensor representations of the input image.\ncontent_image = K.variable(preprocess_image(content_path))\nstyle_image = K.variable(preprocess_image(style_path))\n\ncombination_image = K.variable(preprocess_image(content_path))\n\n\"\"\" Concatenate the Content Image, Style Image and Resultant Image: Results a shape [3, 512, 512, 3]\"\"\"\n# input_tensor = K.concatenate([content_image, style_image, combination_image], axis = 0)\n\n# model = vgg19.VGG19(weights = 'imagenet',  include_top = False)\nmodel = vgg19.VGG19(weights= '../input/vgg-weights/vgg19_notop.h5', include_top=False)\n\noutputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\nfeature_extractors = tf.keras.Model(inputs = model.inputs, outputs = outputs_dict)\n\ncontent_layer = 'block5_conv2'\nstyle_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n\n\n\nstyle_weight = 1e-6\ncontent_weight = 2.5e-8\n\noptimizer = tf.keras.optimizers.SGD(\n  tf.keras.optimizers.schedules.ExponentialDecay(\n      initial_learning_rate=300.0, decay_steps=500, decay_rate=0.96\n  )\n)\n\nresult_prefix = \"Lab_generated\"\n\niterations = 20000\nfor i in range(1, iterations + 1):\n    loss, grads = compute_loss_and_grads(\n        combination_image, content_image, style_image\n    )\n    optimizer.apply_gradients([(grads, combination_image)])\n    if i % 100 == 0:\n        print(\"Iteration %d: loss=%.2f\" % (i, loss))\n        img = deprocess_image(combination_image.numpy())\n        fname = result_prefix + \"_at_iteration_%d.png\" % i\n        tf.keras.preprocessing.image.save_img(fname, img)","metadata":{"id":"mhcGxI3dKCTm","outputId":"9da2042d-b1fb-4ea1-957a-90886ca5bd83","execution":{"iopub.status.busy":"2021-09-23T12:12:20.657785Z","iopub.execute_input":"2021-09-23T12:12:20.658411Z","iopub.status.idle":"2021-09-23T13:06:37.021376Z","shell.execute_reply.started":"2021-09-23T12:12:20.658367Z","shell.execute_reply":"2021-09-23T13:06:37.019428Z"},"trusted":true},"execution_count":null,"outputs":[]}]}